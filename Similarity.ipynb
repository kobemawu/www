{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similarity.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kobemawu/www/blob/master/Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aVVn6hB9Zei"
      },
      "source": [
        "# Preprocessing and calculate similarity\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆã®ç›®æ¨™ã¯è‡ªåŠ›ã§æ–‡æ›¸ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨  \n",
        "æœ€çµ‚çš„ã«Wikipediaã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å›½ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚Š  \n",
        "æ—¥æœ¬ã¨ä¼¼ã¦ã„ã‚‹å›½ã‚’æ¢ã™"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5-315WVmN64",
        "outputId": "7fcd0c1f-389a-4791-a9f2-3254876bd499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8iK7xBDTmtf"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUvXHj7mRls",
        "outputId": "715b4836-8e05-4313-d0e5-cf8e81547343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpg2beFhKA2R"
      },
      "source": [
        "## 1. Calculate similarity\n",
        "\n",
        "ä»¥ä¸‹ã®ä¸‰ã¤ã®æ–‡ã‚’è€ƒãˆã‚‹  \n",
        "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
        "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
        "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
        "\n",
        "Doc Aã¨Doc Bã¯ä¼¼ã¦ã„ãã†ã ãŒã€Doc Cã¯Doc Aã¨ã‚‚Doc Bã¨ã‚‚ä¼¼ã¦ã„ãªã•ãã†  \n",
        "ã“ã‚Œã‚’é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ç¢ºã‹ã‚ã‚‹\n",
        "\n",
        "é¡ä¼¼åº¦ã®è¨ˆç®—ã®ä»•æ–¹ã¯ã„ãã¤ã‹ã‚ã‚‹\n",
        "\n",
        "- é›†åˆãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦\n",
        "  - Jaccardä¿‚æ•°\n",
        "  - Diceä¿‚æ•°\n",
        "  - Simpsonä¿‚æ•°\n",
        "- ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦\n",
        "  - ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\n",
        "  - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rpPCaUeOWE"
      },
      "source": [
        "### é›†åˆãƒ™ãƒ¼ã‚¹\n",
        "\n",
        "æ–‡æ›¸ã‚’å˜èªã®é›†åˆã«å¤‰æ›ã™ã‚‹  \n",
        "é›†åˆãªã®ã§é‡è¤‡ã—ãŸå˜èªã¯å‰Šé™¤ã™ã‚‹  \n",
        "å‰å‡¦ç†ã¯ä»Šå›ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹   \n",
        "\n",
        "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
        "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
        "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
        "â†“    \n",
        "Set A : {'a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'}  \n",
        "Set B : {'an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'}  \n",
        "Set C : {'basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'}  \n",
        "\n",
        "ã“ã®é›†åˆãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’è¡¨ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uts5Ns2eKDaW"
      },
      "source": [
        "#### Jaccardä¿‚æ•°\n",
        "Jaccardä¿‚æ•°ã¯äºŒã¤ã®é›†åˆA,Bã«å¯¾ã—ã¦å®šç¾©ã•ã‚Œã‚‹é¡ä¼¼åº¦ã§ã‚ã‚‹  \n",
        "è¨ˆç®—å¼ã¯ä»¥ä¸‹ã®é€šã‚Š\n",
        "\n",
        "\\begin{equation}\n",
        "J(A,B)=\\dfrac{|A\\cap B|}{|A \\cup B|}\n",
        "\\end{equation}\n",
        "\n",
        "å…±é€šéƒ¨åˆ†ã®å‰²åˆãŒå¤§ãã‘ã‚Œã°ãã®äºŒã¤ã®æ–‡æ›¸ã¯ä¼¼ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqr10Mw-K5UQ"
      },
      "source": [
        "def jaccard_similarity(set_a,set_b):\n",
        "  # ç©é›†åˆã®è¦ç´ æ•°ã‚’è¨ˆç®—\n",
        "  num_intersection = len(set.intersection(set_a, set_b))\n",
        "  # å’Œé›†åˆã®è¦ç´ æ•°ã‚’è¨ˆç®—\n",
        "  num_union = len(set.union(set_a, set_b))\n",
        "  #Jaccardä¿‚æ•°ã‚’ç®—å‡ºã€€ç©ºé›†åˆã®æ™‚ã¯1ã‚’å‡ºåŠ›\n",
        "  try:\n",
        "      return float(num_intersection) / num_union\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0 "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZSFY5urK8eT",
        "outputId": "dd9c93bc-df41-4bce-eb2d-11bdaf7ea098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
        "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
        "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
        "\n",
        "print(\"jaccard(a, b) = \", jaccard_similarity(set_a, set_b)) #Jaccardä¿‚æ•°ã‚’è¨ˆç®—\n",
        "print(\"jaccard(a, c) = \", jaccard_similarity(set_a, set_c))\n",
        "print(\"jaccard(b, c) = \", jaccard_similarity(set_b, set_c))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jaccard(a, b) =  0.5714285714285714\n",
            "jaccard(a, c) =  0.11764705882352941\n",
            "jaccard(b, c) =  0.05555555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXBk5SiTMmGf"
      },
      "source": [
        "\n",
        "nltkã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹  \n",
        "å®šç¾©ã¨åŒã˜ã‚ˆã†ã«è¨ˆç®—ã‚’è¡Œã†ã®ã§ã€å…¥åŠ›ã¯é›†åˆ  \n",
        "è·é›¢ã«ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã«ã¯æ³¨æ„ãŒå¿…è¦"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZQ9q8mFLJTO",
        "outputId": "3333bb6d-0ab3-4865-db8f-9835f2011b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
        "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
        "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
        "\n",
        "# Jaccardè·é›¢ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€é¡ä¼¼åº¦ã«å¤‰æ›ã™ã‚‹ã¨ãã¯1ã‹ã‚‰å¼•ã\n",
        "print(\"jaccard(a, b) = \", 1 - jaccard_distance(set_a, set_b))\n",
        "print(\"jaccard(a, c) = \", 1 - jaccard_distance(set_a, set_c))\n",
        "print(\"jaccard(b, c) = \", 1 - jaccard_distance(set_b, set_c))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jaccard(a, b) =  0.5714285714285714\n",
            "jaccard(a, c) =  0.11764705882352944\n",
            "jaccard(b, c) =  0.05555555555555558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lyCVTfePwB2"
      },
      "source": [
        "#### SÃ¸rensen-Diceä¿‚æ•°\n",
        "\n",
        "Jaccardä¿‚æ•°ã§ã¯åˆ†æ¯ã¯ã®å’Œé›†åˆã§ã‚ã£ãŸãŸã‚  \n",
        "ç‰‡æ–¹ã®é›†åˆãŒã¨ã¦ã‚‚å¤§ãã„ã¨å…±é€šéƒ¨åˆ†ãŒå¤§ããã¦ã‚‚ä¿‚æ•°ã®å€¤ãŒå°ã•ããªã£ã¦ã—ã¾ã†ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹  \n",
        "SÃ¸rensen-Diceä¿‚æ•°ã§ã¯ã€åˆ†æ¯ã‚’äºŒã¤ã®é›†åˆã®å¤§ãã•ã®å¹³å‡ã‚’ã¨ã‚‹ã“ã¨ã§ã€ãã®å½±éŸ¿ã‚’ç·©å’Œã—ã¦ã„ã‚‹  \n",
        "\n",
        "$\n",
        "DSC(A,B) = \\dfrac{|A\\cap B|}{\\dfrac{|A| + |B|}{2}} = \\dfrac{2|A\\cap B|}{|A| + |B|}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M0RikFPR3Qr"
      },
      "source": [
        "def dice_similarity(set_a, set_b):\n",
        "  num_intersection =  len(set.intersection(set_a, set_b))\n",
        "  sum_nums = len(set_a) + len(set_b)\n",
        "  try:\n",
        "    return 2 * num_intersection / sum_nums\n",
        "  except ZeroDivisionError:\n",
        "    return 1.0 "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZQFbXlESPWl",
        "outputId": "cf9b84ba-54a6-4457-e10b-d416537a0de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
        "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
        "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
        "\n",
        "print(\"dice(a, b) = \", dice_similarity(set_a, set_b))\n",
        "print(\"dice(a, c) = \", dice_similarity(set_a, set_c))\n",
        "print(\"dice(b, c) = \", dice_similarity(set_b, set_c))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dice(a, b) =  0.7272727272727273\n",
            "dice(a, c) =  0.21052631578947367\n",
            "dice(b, c) =  0.10526315789473684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtliI-HPwRE"
      },
      "source": [
        "#### Szymkiewicz-Simpsonä¿‚æ•°\n",
        "\n",
        "å·®é›†åˆã®è¦ç´ æ•°ã®å½±éŸ¿ã‚’æ¥µé™ã¾ã§æŠ‘ãˆãŸã®ãŒSzymkiewicz-Simpsonä¿‚æ•°    \n",
        "$\n",
        "overlap(ğ´,ğµ) = \\dfrac{|A\\cap B|}{\\min(|A|, |B|)}\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgGJ5GhmUduH"
      },
      "source": [
        "def simpson_similarity(list_a, list_b):\n",
        "  num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
        "  min_num = min(len(set(list_a)), len(set(list_b)))\n",
        "  try:\n",
        "    return num_intersection / min_num\n",
        "  except ZeroDivisionError:\n",
        "    if num_intersection == 0:\n",
        "      return 1.0\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_1Gjy4IV9eo",
        "outputId": "309b6c29-1d91-47c7-931e-51c6e53ecdd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
        "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
        "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
        "\n",
        "print(\"simpson(a, b) = \", simpson_similarity(set_a, set_b)) \n",
        "print(\"simpson(a, c) = \", simpson_similarity(set_a, set_c)) \n",
        "print(\"simpson(b, c) = \", simpson_similarity(set_b, set_c)) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simpson(a, b) =  0.7272727272727273\n",
            "simpson(a, c) =  0.25\n",
            "simpson(b, c) =  0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-T32gmnZIyt"
      },
      "source": [
        "#### Exercise 1\n",
        "è‰²ã€…ãªé›†åˆã‚’ä½œã£ã¦é›†åˆãƒ™ãƒ¼ã‚¹æ‰‹æ³•ã®æ¯”è¼ƒã‚’ã—ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJwJpZpdYtz9",
        "outputId": "e19e4ff8-baac-4000-aa93-4deb1613f224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
        "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
        "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
        "set_d = set() # å¤§ãã‚ã®é›†åˆã‚’ä½œã£ã¦è©¦ã—ã¦ã¿ã‚ˆã†\n",
        "\n",
        "print(\"jaccard similarity:\")\n",
        "print(jaccard_similarity(set_d, set_a))\n",
        "print(jaccard_similarity(set_d, set_b))\n",
        "print(jaccard_similarity(set_d, set_c))\n",
        "\n",
        "print(\"dice similarity:\")\n",
        "print(dice_similarity(set_d, set_a))\n",
        "print(dice_similarity(set_d, set_b))\n",
        "print(dice_similarity(set_d, set_c))\n",
        "\n",
        "print(\"simpson similarity:\")\n",
        "print(simpson_similarity(set_d, set_a))\n",
        "print(simpson_similarity(set_d, set_b))\n",
        "print(simpson_similarity(set_d, set_c))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jaccard similarity:\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "dice similarity:\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "simpson similarity:\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-Hm34tgXCbh"
      },
      "source": [
        "### ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ \n",
        "\n",
        "\n",
        "æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã—é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹  \n",
        "ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®æ‰‹æ³•ã¯è‰²ã€…ã‚ã‚‹ãŒä»Šå›ã¯BoW(Bag of Words)ã§èª¬æ˜ã™ã‚‹  \n",
        "\n",
        "BoWã¯æ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ã™ã‚‹æ–¹æ³•ã®ä¸€ã¤  \n",
        "æƒ³å®šã—ã¦ã„ã‚‹å˜èªã®ç·æ•°ã‚’Nã¨ã™ã‚‹ã¨ã€å„æ¬¡å…ƒãŒå„å˜èªã«å¯¾å¿œã™ã‚‹Næ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è€ƒãˆã‚‹  \n",
        "å„æ¬¡å…ƒã®å€¤ã¯ãã®å˜èªãŒæ–‡æ›¸ä¸­ã§å‡ºãŸå›æ•°\n",
        "\n",
        "ä¾‹ï¼‰  \n",
        "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
        "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
        "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
        "â†“  \n",
        "å…¨å˜èªã¯19å€‹ã§ã€å„æ¬¡å…ƒã®å€¤ã¯ä»¥ä¸‹ã®å˜èªã®å€‹æ•°ã«å¯¾å¿œã™ã‚‹BoWã‚’è€ƒãˆã‚‹  \n",
        "['an', 'and', 'apple', 'apples', 'basketball', 'bought', 'buy', 'day', 'eat', 'every', 'i', 'jordan', 'like', 'michael', 'play', 'some', 'strawberries', 'tomorrow', 'will']  \n",
        "â†“  \n",
        "BoW A : [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]  \n",
        "BoW B : [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]  \n",
        "BoW C : [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]  \n",
        "\n",
        "ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’è¡¨ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQOjHTfCeXjs"
      },
      "source": [
        "\n",
        "#### ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\n",
        "\n",
        "å„æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã™ã“ã¨ãŒå‡ºæ¥ãŸã®ã§  \n",
        "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãŒè¨ˆç®—ã§ãã‚‹  \n",
        "ã“ã®è·é›¢ãŒå°ã•ã‘ã‚Œã°ä¼¼ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹ã“ã¨ãŒå‡ºæ¥ã‚‹\n",
        "\n",
        "\\begin{equation}\n",
        "d(v_1,v_2) =(\\sum_{i=1}^n (v_{1i}-v_{2i})^2)^{\\frac{1}{2}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtEzuSDKZbpV"
      },
      "source": [
        "def euclidean_distance(list_a, list_b):\n",
        "  diff_vec = np.array(list_a) - np.array(list_b)\n",
        "  return np.linalg.norm(diff_vec)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sr_ZYj7azLV",
        "outputId": "4af5e8a0-3711-4749-f714-d3af7b05e45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bow_a = [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]  \n",
        "bow_b = [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]  \n",
        "bow_c = [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]  \n",
        "\n",
        "print(\"euclidean_distance(bow_a, bow_b) = \",euclidean_distance(bow_a, bow_b))\n",
        "print(\"euclidean_distance(bow_a, bow_c) = \",euclidean_distance(bow_a, bow_c))\n",
        "print(\"euclidean_distance(bow_b, bow_c) = \",euclidean_distance(bow_b, bow_c))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "euclidean_distance(bow_a, bow_b) =  2.23606797749979\n",
            "euclidean_distance(bow_a, bow_c) =  3.7416573867739413\n",
            "euclidean_distance(bow_b, bow_c) =  4.123105625617661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfKcQd5SiBb-"
      },
      "source": [
        "#### ãƒŸãƒ³ã‚³ãƒ•ã‚¹ã‚­ãƒ¼è·é›¢\n",
        "\n",
        "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’ä¸€èˆ¬åŒ–ã—ãŸè·é›¢\n",
        "pã®å€¤ã‚’å¤‰ãˆã‚‹ã“ã¨ã§è‰²ã€…ãªè·é›¢ã‚’è¡¨ç¾ã§ãã‚‹  \n",
        "\n",
        "\\begin{equation}\n",
        "d(v_1,v_2) = (\\sum_{i=1}^n |v_{1i}-v_{2i}|^p)^{\\frac{1}{p}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx46KLSNhjI2"
      },
      "source": [
        "#### Exercise 2\n",
        "ãƒŸãƒ³ã‚³ãƒ•ã‚¹ã‚­ãƒ¼è·é›¢ã‚’è¨ˆç®—ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã„ã¦  \n",
        "p=1,2,3ã§è·é›¢ã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6UMFh58bexH"
      },
      "source": [
        "# np.linalg.normã«ã¤ã„ã¦èª¿ã¹ã‚ˆã†\n",
        "def minkowski_distance(list_a, list_b, p):\n",
        "  ## return 0ã¯ãƒ€ãƒŸãƒ¼ã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚å‰Šé™¤ã—ã¦\n",
        "  ##ã€€è‡ªåˆ†ã§ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
        "  return 0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKMIMbyJc8eH",
        "outputId": "3a03647f-62e0-4746-ccf1-497f6b6ce712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# p=1\n",
        "print(minkowski_distance(bow_a, bow_b, 1))\n",
        "print(minkowski_distance(bow_a, bow_c, 1))\n",
        "print(minkowski_distance(bow_b, bow_c, 1))\n",
        "\n",
        "# p=2\n",
        "print(minkowski_distance(bow_a, bow_b, 2))\n",
        "print(minkowski_distance(bow_a, bow_c, 2))\n",
        "print(minkowski_distance(bow_b, bow_c, 2))\n",
        "\n",
        "# p=3\n",
        "print(minkowski_distance(bow_a, bow_b, 3))\n",
        "print(minkowski_distance(bow_a, bow_c, 3))\n",
        "print(minkowski_distance(bow_b, bow_c, 3))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIyabGRTKGwA"
      },
      "source": [
        "#### ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦\n",
        "\n",
        "ãƒ™ã‚¯ãƒˆãƒ«ã®ãªã™è§’ã«ç€ç›®ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹  \n",
        "\n",
        "\\begin{equation}\n",
        "similarity(A, B)=cos(\\theta)=\\dfrac{\\sum_{i=1}^n A_iB_i}{{\\sqrt A}{\\sqrt B}}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fWy619amlwp"
      },
      "source": [
        "#### Exercise 3\n",
        "ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã„ã¦è¨ˆç®—ã—ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDhwqTN5yJGQ"
      },
      "source": [
        "# numpy.array ã«ã¤ã„ã¦èª¿ã¹ã‚ˆã†\n",
        "def cosine_similarity(list_a, list_b):\n",
        "  # ã‚ã¨ã§æ¶ˆã™\n",
        "  inner_prod = np.array(list_a).dot(np.array(list_b))\n",
        "  norm_a = np.linalg.norm(list_a)\n",
        "  norm_b = np.linalg.norm(list_b)\n",
        "  try:\n",
        "      return inner_prod / (norm_a*norm_b)\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sew3u-YezRrX",
        "outputId": "8bf38eb0-5a79-4c78-81e8-72cc2b6f8f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bow_a = [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]\n",
        "bow_b = [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]\n",
        "bow_c = [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]\n",
        "\n",
        "print(\"cosine_similarity(bow_a, bow_b) = \",cosine_similarity(bow_a, bow_b))\n",
        "print(\"cosine_similarity(bow_a, bow_c) = \",cosine_similarity(bow_a, bow_c))\n",
        "print(\"cosine_similarity(bow_b, bow_c) = \",cosine_similarity(bow_b, bow_c))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine_similarity(bow_a, bow_b) =  0.8153742483272114\n",
            "cosine_similarity(bow_a, bow_c) =  0.41812100500354543\n",
            "cosine_similarity(bow_b, bow_c) =  0.3223291856101521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao0jywXqKIFS"
      },
      "source": [
        "### é›†åˆãƒ™ãƒ¼ã‚¹ã¨ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒ\n",
        "\n",
        "é›†åˆæ¼”ç®—ã®æ–¹ã¯ä¸€ã¤ä¸€ã¤ã®æ–‡æ›¸ãŒå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ€§èƒ½ãŒé«˜ã„  \n",
        "æ–‡æ›¸ãŒã‚ã‚‹ç¨‹åº¦å¤§ãããªã‚‹ã¨ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®æ–¹ãŒæœ‰ç”¨ã«ãªã‚‹  \n",
        "ãã®ä»£ã‚ã‚Šã€èªå½™é›†åˆãŒå¤§ãããªã‚Šè¨ˆç®—é‡ãŒå¤§ãããªã£ã¦ã—ã¾ã†\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1IXMwIyhU-6"
      },
      "source": [
        "### Exercise 4\n",
        "çŸ­ã„æ–‡ç« ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨é•·ã„æ–‡ç« ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªåˆ†ã§ä½œã‚Š    \n",
        "Jaccardä¿‚æ•°ã¨ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦æ¯”è¼ƒã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpkcXVDBhZg8"
      },
      "source": [
        "short_docs = []\n",
        "long_docs = []"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuXSHk01KLza"
      },
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "é›†åˆé–“ã®å…±é€šéƒ¨åˆ†ã‚„ãƒ™ã‚¯ãƒˆãƒ«é–“ã®è·é›¢ã‚„è§’åº¦ã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã“ã¨ãŒå‡ºæ¥ãŸ  \n",
        "é›†åˆã‚„ãƒ™ã‚¯ãƒˆãƒ«ãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’ä¸Šæ‰‹ãè¡¨ã›ã¦ã„ãªã„ã¨é¡ä¼¼åº¦ãŒä¸Šæ‰‹ãæ¸¬ã‚Œãªã„  \n",
        "æ–‡æ›¸ã‹ã‚‰ã©ã®ã‚ˆã†ã«é›†åˆã‚„ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚‹ã‹ãŒã¨ã¦ã‚‚å¤§äº‹  \n",
        " \n",
        "é©åˆ‡ãªå‰å‡¦ç†ã‚’è¡Œã†ã“ã¨ã§ç‰¹å¾´ã‚’æ‰ãˆãŸé¡ä¼¼åº¦ã‚’æ¸¬ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹    \n",
        "å¾ŒåŠã¯ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«çµã£ã¦ç·´ç¿’ã—ã¦ã„ã  \n",
        "\n",
        "1. Clearning\n",
        "2. Tokenize\n",
        "3. Stemming\n",
        "4. Remove stop words\n",
        "5. Vectorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ispTSLKM-z"
      },
      "source": [
        "### 2-1. Clearning\n",
        "\n",
        "ä¸Šã®ä¾‹ã§ã¯ç¶ºéº—ãªæ–‡ç« ã°ã‹ã‚Šæ‰±ã£ã¦ã„ãŸãŒã€å®Ÿéš›ã¯ã‚‚ã£ã¨æ±šã„   \n",
        "Webã‹ã‚‰å–ã£ã¦ããŸãƒ‡ãƒ¼ã‚¿ã ã¨htmlã‚¿ã‚°ãŒæ®‹ã£ã¦ã„ãŸã‚Šã€å¤‰ãªè¨˜å·ãŒå…¥ã£ã¦ã„ãŸã‚Šã™ã‚‹  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM-e5AZT316r"
      },
      "source": [
        "documents=[\"I like apples and a strawberries. I will buy an apple tomorrow @Fresco.\",\n",
        "           \"I bought some apples and strawberries. I will eat an apple <b>tomorrow.</b>\",\n",
        "           \"I play basketball every day. I like Michael Jordan (born February 17, 1963).\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh56eU_levzv"
      },
      "source": [
        "ä»Šã¯ä¸‰ã¤ãªã®ã§æ‰‹å‹•ã§æ¶ˆã›ã‚‹ãŒ  \n",
        "å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã¨ãã«ã¯è‡ªå‹•ã§ç¶ºéº—ã«ã§ããªã„ã¨ã„ã‘ãªã„  \n",
        "ç¶ºéº—ã«ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œã‚‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06coot4PnVgS"
      },
      "source": [
        "#### Exercise 5\n",
        "\n",
        "æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶ºéº—ã«ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã“ã†\n",
        "\n",
        "å‚è€ƒ: æ­£è¦è¡¨ç¾ (https://uxmilk.jp/41416)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt3NL8Ux5Q4E",
        "outputId": "c058f8b0-a75a-4f62-f449-6c72fbc98841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def cleaning_text(text):\n",
        "    # @ã®å‰Šé™¤\n",
        "    pattern1 = '@'\n",
        "    text = re.sub(pattern1, '', text)    \n",
        "    # <b>ã‚¿ã‚°ã®å‰Šé™¤ã€€\n",
        "    # æ¬¡ã®è¡Œã®'#'ã‚’å‰Šé™¤ã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚\n",
        "    pattern2 = '</?b>'# \n",
        "    text = re.sub(pattern2, '', text)    \n",
        "    # ()å†…ã‚’å‰Šé™¤\n",
        "    # æ¬¡ã®è¡Œã®'#'ã‚’å‰Šé™¤ã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚\n",
        "    pattern3 = '\\((.*)\\)'#\n",
        "    text = re.sub(pattern3, '', text)\n",
        "    return text\n",
        "  \n",
        "\n",
        "for text in documents:\n",
        "    print(cleaning_text(text))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like apples and a strawberries. I will buy an apple tomorrow Fresco.\n",
            "I bought some apples and strawberries. I will eat an apple tomorrow.\n",
            "I play basketball every day. I like Michael Jordan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcgcKWkRflR5"
      },
      "source": [
        "#### Option 1\n",
        "\n",
        "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶ºéº—ã«ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã¿ã‚ˆã†\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcsdHgV-h26y"
      },
      "source": [
        "text = '<p><b>Natural language processing</b> (<b>NLP</b>) is a subfield of <a href=\"/wiki/Computer_science\" title=\"Computer science\">computer science</a>, <a href=\"/wiki/Information_engineering_(field)\" title=\"Information engineering (field)\">information engineering</a>, and <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of <a href=\"/wiki/Natural_language\" title=\"Natural language\">natural language</a> data.</p>'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1doxCMAGr0_O"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edJ80nTbQgLi"
      },
      "source": [
        "\n",
        "### 2-2. Tokenize\n",
        "\n",
        "ã¾ã æ–‡å­—åˆ—ã®ã¾ã¾ãªã®ã§ã€å˜èªã”ã¨ã«åŒºåˆ‡ã‚‹  \n",
        "è‹±èªã ã¨ç©ºç™½åŒºåˆ‡ã‚Šã§ã‚ˆã„ãŒæ—¥æœ¬èªã ã¨å°‘ã—é¢å€’  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGbqTvkyYl2S",
        "outputId": "171d8130-7be6-4e96-a0a9-94292a999666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def tokenize_text(text):\n",
        "  text = re.sub('[.,]', '', text)\n",
        "  return text.split()\n",
        "\n",
        "for text in documents:\n",
        "  text = cleaning_text(text)\n",
        "  print(tokenize_text(text))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'apples', 'and', 'a', 'strawberries', 'I', 'will', 'buy', 'an', 'apple', 'tomorrow', 'Fresco']\n",
            "['I', 'bought', 'some', 'apples', 'and', 'strawberries', 'I', 'will', 'eat', 'an', 'apple', 'tomorrow']\n",
            "['I', 'play', 'basketball', 'every', 'day', 'I', 'like', 'Michael', 'Jordan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K97zCvZBQik9"
      },
      "source": [
        "### 2-3. Stemming, Lemmatize\n",
        "\n",
        "åŒã˜æ„å‘³ã®å˜èªã§ã‚‚ç•°ãªã‚‹å½¢ã‚’ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚‹  \n",
        "ãã‚Œã‚‰ã‚’åˆ¥ã®å˜èªã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã®ã¯ä¸è‡ªç„¶  \n",
        "å°æ–‡å­—ã«å¤‰æ›ã—ãŸå¾Œ  \n",
        "Stemmingã‚„Lemmatizeã¨ã„ã†å‡¦ç†ã§åŒã˜å½¢ã«ã™ã‚‹  \n",
        "ä»Šå›ã¯Lemmatizeã®ã¿"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7R55rKxZtAz"
      },
      "source": [
        "from nltk.corpus import wordnet as wn #lemmatizeé–¢æ•°ã®ãŸã‚ã®import\n",
        "\n",
        "def lemmatize_word(word):\n",
        "    # make words lower  example: Python =>python\n",
        "    word=word.lower()\n",
        "    \n",
        "    # lemmatize  example: cooked=>cook\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "      return lemma"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0sEVvmwaCqA",
        "outputId": "c71443cd-4542-428d-f0cf-c5e9511195a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for text in documents:\n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  print([lemmatize_word(word) for word in tokens])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'like', 'apple', 'and', 'a', 'strawberry', 'i', 'will', 'buy', 'an', 'apple', 'tomorrow', 'fresco']\n",
            "['i', 'buy', 'some', 'apple', 'and', 'strawberry', 'i', 'will', 'eat', 'an', 'apple', 'tomorrow']\n",
            "['i', 'play', 'basketball', 'every', 'day', 'i', 'like', 'michael', 'jordan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOPIFqvjfxEg"
      },
      "source": [
        "strawberriesâ†’strawberryã®ã‚ˆã†ã«èªã‚’æ¨™æº–å½¢ã«å¤‰æ›å‡ºæ¥ãŸ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpUxnB9kQlKv"
      },
      "source": [
        "### 2-4. Remove stop words\n",
        "\n",
        "a, theãªã©ã®æ–‡ç« ã«å¯„ã‚‰ãšä¸€èˆ¬çš„ã«ä½¿ã‚ã‚Œã‚‹å† è©ã€ä»£åè©ã€å‰ç½®è©ãªã©ã‚’ä½¿ã£ã¦ã‚‚æ„å‘³ãŒãªã„  \n",
        "ãã‚Œã‚‰ã®å˜èªã¯stop wordã¨å‘¼ã°ã‚Œã‚‹  \n",
        "nltkã«ã¯å°‚é–€å®¶ãŒå®šç¾©ã—ãŸstop wordã®ãƒªã‚¹ãƒˆãŒã‚ã‚‹ã®ã§ãã‚Œã‚’ä½¿ã†  \n",
        "å¿…è¦ã«å¿œã˜ã¦stop wordã¯è‡ªåˆ†ã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã¹ã  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbSLDay-a36N",
        "outputId": "403d24ce-dcfb-463a-d8f7-820adb392d28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#1 nltkã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ\n",
        "en_stop = nltk.corpus.stopwords.words('english')\n",
        "print(en_stop)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX8eIyxfbo6q"
      },
      "source": [
        "def remove_stopwords(word, stopwordset):\n",
        "  if word in stopwordset:\n",
        "    return None\n",
        "  else:\n",
        "    return word"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WckIX0ThbQMy",
        "outputId": "e14f89ac-2b08-48aa-b7c3-624207604bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for text in documents:\n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  print([remove_stopwords(word, en_stop) for word in tokens])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 'like', 'apple', None, None, 'strawberry', None, None, 'buy', None, 'apple', 'tomorrow', 'fresco']\n",
            "[None, 'buy', None, 'apple', None, 'strawberry', None, None, 'eat', None, 'apple', 'tomorrow']\n",
            "[None, 'play', 'basketball', 'every', 'day', None, 'like', 'michael', 'jordan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4kNHhr5f8Vt"
      },
      "source": [
        "ä»Šå›ã¯ã“ã‚Œã ã‘ã§çµ‚ã‚ã‚Šã«ã™ã‚‹ãŒå˜èªã®å‰Šé™¤ã¯ã‹ãªã‚Šé‡è¦  \n",
        "å‡ºç¾é »åº¦ãŒæ¥µç«¯ã«ä½ã„å˜èªã‚’å‰Šé™¤ã—ãŸã‚Šã€å‹•è©ã¨åè©ã«é™å®šã™ã‚‹ãªã©è‰²ã€…ã‚ã‚‹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgjfOITFxwx_",
        "outputId": "284a0284-9c89-43c5-ebc6-45adc0fbb3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def preprocessing_text(text):\n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
        "  tokens = [word for word in tokens if word is not None]\n",
        "  return tokens\n",
        "\n",
        "\n",
        "preprocessed_docs = [preprocessing_text(text) for text in documents]\n",
        "preprocessed_docs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['like', 'apple', 'strawberry', 'buy', 'apple', 'tomorrow', 'fresco'],\n",
              " ['buy', 'apple', 'strawberry', 'eat', 'apple', 'tomorrow'],\n",
              " ['play', 'basketball', 'every', 'day', 'like', 'michael', 'jordan']]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCd6YpYbKJSJ"
      },
      "source": [
        "### 2-5. Vectorize\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmrBtgPxcwX0"
      },
      "source": [
        "#### BoW(Bag of Words)\n",
        "\n",
        "\n",
        "ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã®å‡ºç¾å›æ•°ã®ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã—ãŸã‚‚ã®  \n",
        "äººæ‰‹ã§å˜èªã‚’æ•°ãˆãŸã‚Šã™ã‚‹ã®ã¯ä¸å¯èƒ½ãªã®ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‡¦ç†ã‚’å®Œçµã—ã¦ã—ã¾ãŠã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S69MsPjHcvut"
      },
      "source": [
        "def bow_vectorizer(docs):\n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "        \n",
        "  result_list = []\n",
        "  for doc in docs:\n",
        "    doc_vec = [0] * len(word2id)\n",
        "    for w in doc:\n",
        "      doc_vec[word2id[w]] += 1\n",
        "    result_list.append(doc_vec)\n",
        "  return result_list, word2id"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq3TpP7KO-XP",
        "outputId": "6c1f8b2e-d8f8-4796-897d-b1cd389ba4c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bow_vec, word2id = bow_vectorizer(preprocessed_docs)\n",
        "print(bow_vec)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udTTbKv8oFpG",
        "outputId": "7edf785a-0d71-484d-b376-2418e01b1e1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2id.items()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('like', 0), ('apple', 1), ('strawberry', 2), ('buy', 3), ('tomorrow', 4), ('fresco', 5), ('eat', 6), ('play', 7), ('basketball', 8), ('every', 9), ('day', 10), ('michael', 11), ('jordan', 12)])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e8h1SMTcyD5"
      },
      "source": [
        "### TF-IDF(Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "BoWã§ã¯å„å˜èªã®é‡ã¿ãŒåŒã˜ã ã£ãŸãŒã€å˜èªã«ã‚ˆã£ã¦é‡è¦åº¦ã¯å¤‰ã‚ã‚‹  \n",
        "å˜èªã®é‡è¦åº¦ã‚’è€ƒæ…®ã—ãŸã®ãŒTF-IDF  \n",
        "\n",
        "TF(t, d) = ã‚ã‚‹å˜èª(t)ã®ã‚ã‚‹æ–‡æ›¸(d)ã«ãŠã‘ã‚‹å‡ºç¾é »åº¦  \n",
        "IDF(t) = ã‚ã‚‹å˜èª(t)ãŒå…¨æ–‡æ›¸é›†åˆ(D)ä¸­ã«ã©ã‚Œã ã‘ã®æ–‡æ›¸ã§å‡ºç¾ã—ãŸã‹ã®é€†æ•°  \n",
        "\n",
        "TF-IDF(t,d) = TF(t, d) * IDF(t)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiKn2p7Bc0bN"
      },
      "source": [
        "def tfidf_vectorizer(docs):\n",
        "  def tf(word2id, doc):\n",
        "    term_counts = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      term_counts[word2id[term]] = doc.count(term)\n",
        "    tf_values = list(map(lambda x: x/sum(term_counts), term_counts))\n",
        "    return tf_values\n",
        "  \n",
        "  def idf(word2id, docs):\n",
        "    idf = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      idf[word2id[term]] = np.log(len(docs) / sum([bool(term in doc) for doc in docs]))\n",
        "    return idf\n",
        "  \n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "  \n",
        "  return [[_tf*_idf for _tf, _idf in zip(tf(word2id, doc), idf(word2id, docs))] for doc in docs], word2id\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz5YnQZclGfL",
        "outputId": "36a22fd1-7344-44c8-90cc-b23762962bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_vector, word2id = tfidf_vectorizer(preprocessed_docs)\n",
        "print(tfidf_vector)\n",
        "print(word2id.items())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05792358687259491, 0.11584717374518982, 0.05792358687259491, 0.05792358687259491, 0.05792358687259491, 0.15694461266687282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.13515503603605478, 0.06757751801802739, 0.06757751801802739, 0.06757751801802739, 0.0, 0.1831020481113516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05792358687259491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282]]\n",
            "dict_items([('like', 0), ('apple', 1), ('strawberry', 2), ('buy', 3), ('tomorrow', 4), ('fresco', 5), ('eat', 6), ('play', 7), ('basketball', 8), ('every', 9), ('day', 10), ('michael', 11), ('jordan', 12)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxCJEOjXYSIP"
      },
      "source": [
        "### Exercise 6\n",
        "BoWã¨TF-IDFã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ãã‚Œãã‚Œè¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD4nID08s-21"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAUfDUOmJMsp"
      },
      "source": [
        "### Option 2\n",
        "scikit-learn, nltk gensimãã‚Œãã‚Œã«TF-IDFã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ãŒã‚ã‚‹  \n",
        "ãã‚Œãã‚Œã§TF-IDFã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2tZLjHNxRDG"
      },
      "source": [
        "# scikit-learnã®tfidfã€€ã‚ã¨ã§æ¶ˆã™\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x7nd2-ekIs-",
        "outputId": "95e7002f-dbb2-4414-ecc2-6e10b474b8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#nltk ã®tf-idfã€€ã‚ã¨ã§æ¶ˆã™\n",
        "collection = nltk.TextCollection(preprocessed_docs)\n",
        "terms = list(set(collection))\n",
        "nltk_vector = []\n",
        "for doc in preprocessed_docs:\n",
        "  tmp_vec = np.zeros(len(word2id))\n",
        "  for term in word2id.keys():\n",
        "    tmp_vec[word2id[term]] = collection.tf_idf(term, doc)\n",
        "  nltk_vector.append(list(tmp_vec))\n",
        "print(nltk_vector)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05792358687259491, 0.11584717374518982, 0.05792358687259491, 0.05792358687259491, 0.05792358687259491, 0.15694461266687282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.13515503603605478, 0.06757751801802739, 0.06757751801802739, 0.06757751801802739, 0.0, 0.1831020481113516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05792358687259491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282, 0.15694461266687282]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEyOY2eQkRMc",
        "outputId": "be4baaec-51b7-4d3f-b76c-214c3eeb8807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#gensim tf-idf ã‚ã¨ã§æ¶ˆã™\n",
        "from gensim import corpora\n",
        "from gensim import models\n",
        "\n",
        "dictionary = corpora.Dictionary(preprocessed_docs)\n",
        "print('===å˜èª->idã®å¤‰æ›è¾æ›¸===')\n",
        "print(dictionary.token2id)\n",
        "print(word2id)\n",
        "\n",
        "corpus = list(map(dictionary.doc2bow, preprocessed_docs))\n",
        "test_model = models.TfidfModel(corpus)\n",
        "corpus_tfidf = test_model[corpus]\n",
        "\n",
        "print('===çµæœè¡¨ç¤º===')\n",
        "gensim_vector = []\n",
        "for doc in corpus_tfidf:\n",
        "  tmp_vec = [0] * len(word2id)\n",
        "  for word in doc:\n",
        "    key = dictionary[word[0]]\n",
        "    tmp_vec[word2id[key]] = word[1]\n",
        "  gensim_vector.append(tmp_vec)\n",
        "\n",
        "print(gensim_vector)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===å˜èª->idã®å¤‰æ›è¾æ›¸===\n",
            "{'apple': 0, 'buy': 1, 'fresco': 2, 'like': 3, 'strawberry': 4, 'tomorrow': 5, 'eat': 6, 'basketball': 7, 'day': 8, 'every': 9, 'jordan': 10, 'michael': 11, 'play': 12}\n",
            "{'like': 0, 'apple': 1, 'strawberry': 2, 'buy': 3, 'tomorrow': 4, 'fresco': 5, 'eat': 6, 'play': 7, 'basketball': 8, 'every': 9, 'day': 10, 'michael': 11, 'jordan': 12}\n",
            "===çµæœè¡¨ç¤º===\n",
            "[[0.25530938246616874, 0.5106187649323375, 0.25530938246616874, 0.25530938246616874, 0.25530938246616874, 0.6917636545800514, 0, 0, 0, 0, 0, 0, 0], [0, 0.528121006538623, 0.2640605032693115, 0.2640605032693115, 0.2640605032693115, 0, 0.7154749152081473, 0, 0, 0, 0, 0, 0], [0.1489905855640844, 0, 0, 0, 0, 0, 0, 0.40369167389095173, 0.40369167389095173, 0.40369167389095173, 0.40369167389095173, 0.40369167389095173, 0.40369167389095173]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMjo7F6ZKOW1"
      },
      "source": [
        "## Exercise 7\n",
        "\n",
        "æ§˜ã€…ãªå›½ã®Wikipediaã«ãŠã‘ã‚‹abstractã‚’å–ã‚Šå‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨æ„ã—ãŸ  \n",
        "https://drive.google.com/open?id=1i7tekPQRKaAwg-ze3kv5IsufMW13LkLo  \n",
        "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†  \n",
        "\n",
        "Cosineé¡ä¼¼åº¦ã®è¨ˆç®—ã‚’è¡Œã„ã€Japanã«ä¼¼ã¦ã„ã‚‹å›½Top5ã‚’è¡¨ç¤ºã—ã¦ã¿ã‚ˆã†  \n",
        "å‰å‡¦ç†ã‚’è‡ªåˆ†ãªã‚Šã«å·¥å¤«ã™ã‚‹ã“ã¨  \n",
        "æ³¨ï¼‰é¡ä¼¼åº¦ã¯ã‚ã¾ã‚Šé«˜ããªã‚‰ãªãã¦ã‚‚è‰¯ã„  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bDcIqK4Yc9_l",
        "outputId": "2357e309-ddbb-47a3-88a3-d4d6f226bb01"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1IbA30KKElT",
        "outputId": "2c5f06e8-9070-4aa3-9bbc-47fba80ec564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "df = pd.read_csv(\"./nlp_country.csv\")\n",
        "df"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Name                                           Abstract\n",
              "0           Japan  Japan is an island country in East Asia. Locat...\n",
              "1   United States  The United States of America (USA), commonly k...\n",
              "2         England  England is a country that is part of the Unite...\n",
              "3           China  China, officially the People's Republic of Chi...\n",
              "4           India  India, also known as the Republic of India,[19...\n",
              "5           Korea  Korea is a region in East Asia.[3] Since 1948 ...\n",
              "6         Germany  Germany, officially the Federal Republic of Ge...\n",
              "7          Russia  Russia, or the Russian Federation[12], is a tr...\n",
              "8          France  France, officially the French Republic, is a c...\n",
              "9           Italy  Italy, officially the Italian Republic,[10][11...\n",
              "10         Brazil  Brazil officially the Federative Republic of B...\n",
              "11         Canada  Canada is a country in the northern part of No...\n",
              "12          Spain  Spain, officially the Kingdom of Spain[11][a][...\n",
              "13      Australia  Australia, officially the Commonwealth of Aust...\n",
              "14      Indonesia  Indonesia, officially the Republic of Indonesi...\n",
              "15         Mexico  Mexico, officially the United Mexican States (..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-331b8394-f1ba-47e6-8410-686470c84939\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Japan</td>\n",
              "      <td>Japan is an island country in East Asia. Locat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>United States</td>\n",
              "      <td>The United States of America (USA), commonly k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>England</td>\n",
              "      <td>England is a country that is part of the Unite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China</td>\n",
              "      <td>China, officially the People's Republic of Chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>India</td>\n",
              "      <td>India, also known as the Republic of India,[19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Korea</td>\n",
              "      <td>Korea is a region in East Asia.[3] Since 1948 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Germany</td>\n",
              "      <td>Germany, officially the Federal Republic of Ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Russia</td>\n",
              "      <td>Russia, or the Russian Federation[12], is a tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>France</td>\n",
              "      <td>France, officially the French Republic, is a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Italy</td>\n",
              "      <td>Italy, officially the Italian Republic,[10][11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Brazil</td>\n",
              "      <td>Brazil officially the Federative Republic of B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Canada</td>\n",
              "      <td>Canada is a country in the northern part of No...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Spain</td>\n",
              "      <td>Spain, officially the Kingdom of Spain[11][a][...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Australia</td>\n",
              "      <td>Australia, officially the Commonwealth of Aust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Indonesia</td>\n",
              "      <td>Indonesia, officially the Republic of Indonesi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Mexico</td>\n",
              "      <td>Mexico, officially the United Mexican States (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-331b8394-f1ba-47e6-8410-686470c84939')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-331b8394-f1ba-47e6-8410-686470c84939 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-331b8394-f1ba-47e6-8410-686470c84939');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ZqrWJhBAO2",
        "outputId": "420d8537-ff1c-497a-bcbe-b187640ce49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "df.iloc[0][\"Abstract\"]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Japan is an island country in East Asia. Located in the Pacific Ocean, it lies off the eastern coast of the Asian continent and stretches from the Sea of Okhotsk in the north to the East China Sea and the Philippine Sea in the south. The kanji that make up Japan\\'s name mean \\'sun origin\\', and it is often called the \"Land of the Rising Sun\". Japan is a stratovolcanic archipelago consisting of about 6,852 islands. The four largest are Honshu, Hokkaido, Kyushu, and Shikoku, which make up about ninety-seven percent of Japan\\'s land area and often are referred to as home islands. The country is divided into 47 prefectures in eight regions, with Hokkaido being the northernmost prefecture and Okinawa being the southernmost one. Japan is the 2nd most populous island country. The population of 127 million is the world\\'s eleventh largest, of which 98.5% are ethnic Japanese. 90.7% of people live in cities, while 9.3% live in the countryside.[16] About 13.8 million people live in Tokyo,[17] the capital of Japan. The Greater Tokyo Area is the most populous metropolitan area in the world with over 38 million people.[18] Archaeological research indicates that Japan was inhabited as early as the Upper Paleolithic period. The first written mention of Japan is in Chinese history texts from the 1st century AD. Influence from other regions, mainly China, followed by periods of isolation, particularly from Western Europe, has characterized Japan\\'s history. From the 12th century until 1868, Japan was ruled by successive feudal military shÅguns who ruled in the name of the Emperor. Japan entered into a long period of isolation in the early 17th century, which was ended in 1853 when a United States fleet pressured Japan to open to the West. After nearly two decades of internal conflict and insurrection, the Imperial Court regained its political power in 1868 through the help of several clans from ChÅshÅ« and Satsuma â€“ and the Empire of Japan was established. In the late 19th and early 20th centuries, victories in the First Sino-Japanese War, the Russo-Japanese War and World War I allowed Japan to expand its empire during a period of increasing militarism. The Second Sino-Japanese War of 1937 expanded into part of World War II in 1941, which came to an end in 1945 following the Japanese surrender. Since adopting its revised constitution on May 3, 1947, during the occupation led by SCAP, the sovereign state of Japan has maintained a unitary parliamentary constitutional monarchy with an Emperor and an elected legislature called the National Diet. Japan is a member of the ASEAN Plus mechanism, UN, the OECD, the G7, the G8, and the G20, and is considered a great power.[19][20][21] Its economy is the world\\'s third-largest by nominal GDP and the fourth-largest by purchasing power parity. It is also the world\\'s fourth-largest exporter and fourth-largest importer. Japan benefits from a highly skilled and educated workforce; it has among the world\\'s largest proportion of citizens holding a tertiary education degree.[22] Although it has officially renounced its right to declare war, Japan maintains a modern military with the world\\'s eighth-largest military budget,[23] used for self-defense and peacekeeping roles; it ranked as the world\\'s fourth most-powerful military in 2015.[24] Japan is a highly developed country with a very high standard of living and Human Development Index. Its population enjoys the highest life expectancy and third lowest infant mortality rate in the world, but is experiencing issues due to an aging population and low birthrate. Japan is renowned for its historical and extensive cinema, influential music industry, anime, video gaming, rich cuisine and its major contributions to science and modern technology.[25][26]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPuzoxCacBZJ",
        "outputId": "21eb0f11-5ce4-4202-9203-3e5117f45874"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpQzg57nSAT2"
      },
      "source": [
        "# å¾Œã§æ¶ˆã™\n",
        "def preprocessing_text(text):\n",
        "  def cleaning_text(text):\n",
        "    # @ã®å‰Šé™¤\n",
        "    pattern1 = '@|%'\n",
        "    text = re.sub(pattern1, '', text)    \n",
        "    pattern2 = '\\[[0-9 ]*\\]'\n",
        "    text = re.sub(pattern2, '', text)    \n",
        "    # <b>ã‚¿ã‚°ã®å‰Šé™¤\n",
        "    pattern3 = '\\([a-z ]*\\)'\n",
        "    text = re.sub(pattern3, '', text)    \n",
        "    pattern4 = '[0-9]'\n",
        "    text = re.sub(pattern4, '', text)\n",
        "    return text\n",
        "  \n",
        "  def tokenize_text(text):\n",
        "    text = re.sub('[.,]', '', text)\n",
        "    return text.split()\n",
        "\n",
        "  def lemmatize_word(word):\n",
        "    # make words lower  example: Python =>python\n",
        "    word=word.lower()\n",
        "    \n",
        "    # lemmatize  example: cooked=>cook\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "      return lemma\n",
        "    \n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
        "  tokens = [word for word in tokens if word is not None]\n",
        "  return tokens\n",
        "  \n",
        "docs = df[\"Abstract\"].values\n",
        "pp_docs = [preprocessing_text(text) for text in docs]\n",
        "tfidf_vector, word2id = tfidf_vectorizer(pp_docs)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNzPIvaxPOv5",
        "outputId": "cad9d18a-222c-4458-85a5-66d45539ac5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2id.items()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('japan', 0), ('island', 1), ('country', 2), ('east', 3), ('asia', 4), ('locate', 5), ('pacific', 6), ('ocean', 7), ('lie', 8), ('eastern', 9), ('coast', 10), ('asian', 11), ('continent', 12), ('stretch', 13), ('sea', 14), ('okhotsk', 15), ('north', 16), ('china', 17), ('philippine', 18), ('south', 19), ('kanji', 20), ('make', 21), (\"japan's\", 22), ('name', 23), ('mean', 24), (\"'sun\", 25), (\"origin'\", 26), ('often', 27), ('call', 28), ('\"land', 29), ('rising', 30), ('sun\"', 31), ('stratovolcanic', 32), ('archipelago', 33), ('consist', 34), ('four', 35), ('large', 36), ('honshu', 37), ('hokkaido', 38), ('kyushu', 39), ('shikoku', 40), ('ninety-seven', 41), ('percent', 42), ('land', 43), ('area', 44), ('refer', 45), ('home', 46), ('divide', 47), ('prefecture', 48), ('eight', 49), ('region', 50), ('northernmost', 51), ('okinawa', 52), ('southernmost', 53), ('one', 54), ('nd', 55), ('populous', 56), ('population', 57), ('million', 58), (\"world's\", 59), ('eleventh', 60), ('ethnic', 61), ('japanese', 62), ('people', 63), ('live', 64), ('city', 65), ('countryside', 66), ('tokyo', 67), ('capital', 68), ('greater', 69), ('metropolitan', 70), ('world', 71), ('archaeological', 72), ('research', 73), ('indicate', 74), ('wa', 75), ('inhabit', 76), ('early', 77), ('upper', 78), ('paleolithic', 79), ('period', 80), ('first', 81), ('write', 82), ('mention', 83), ('chinese', 84), ('history', 85), ('text', 86), ('st', 87), ('century', 88), ('ad', 89), ('influence', 90), ('mainly', 91), ('follow', 92), ('isolation', 93), ('particularly', 94), ('western', 95), ('europe', 96), ('ha', 97), ('characterize', 98), ('th', 99), ('rule', 100), ('successive', 101), ('feudal', 102), ('military', 103), ('shÅguns', 104), ('emperor', 105), ('enter', 106), ('long', 107), ('end', 108), ('unite', 109), ('state', 110), ('fleet', 111), ('pressure', 112), ('open', 113), ('west', 114), ('nearly', 115), ('two', 116), ('decade', 117), ('internal', 118), ('conflict', 119), ('insurrection', 120), ('imperial', 121), ('court', 122), ('regain', 123), ('political', 124), ('power', 125), ('help', 126), ('several', 127), ('clan', 128), ('chÅshÅ«', 129), ('satsuma', 130), ('â€“', 131), ('empire', 132), ('establish', 133), ('late', 134), ('victory', 135), ('sino-japanese', 136), ('war', 137), ('russo-japanese', 138), ('allow', 139), ('expand', 140), ('increase', 141), ('militarism', 142), ('second', 143), ('part', 144), ('ii', 145), ('come', 146), ('following', 147), ('surrender', 148), ('since', 149), ('adopt', 150), ('revise', 151), ('constitution', 152), ('may', 153), ('occupation', 154), ('led', 155), ('scap', 156), ('sovereign', 157), ('maintain', 158), ('unitary', 159), ('parliamentary', 160), ('constitutional', 161), ('monarchy', 162), ('elect', 163), ('legislature', 164), ('national', 165), ('diet', 166), ('member', 167), ('asean', 168), ('plus', 169), ('mechanism', 170), ('un', 171), ('oecd', 172), ('g', 173), ('consider', 174), ('great', 175), ('economy', 176), ('third-largest', 177), ('nominal', 178), ('gdp', 179), ('fourth-largest', 180), ('purchasing', 181), ('parity', 182), ('also', 183), ('exporter', 184), ('importer', 185), ('benefit', 186), ('highly', 187), ('skilled', 188), ('educate', 189), ('workforce;', 190), ('among', 191), ('proportion', 192), ('citizen', 193), ('holding', 194), ('tertiary', 195), ('education', 196), ('degree', 197), ('although', 198), ('officially', 199), ('renounce', 200), ('right', 201), ('declare', 202), ('modern', 203), ('eighth-largest', 204), ('budget', 205), ('use', 206), ('self-defense', 207), ('peacekeeping', 208), ('roles;', 209), ('rank', 210), ('fourth', 211), ('most-powerful', 212), ('develop', 213), ('high', 214), ('standard', 215), ('living', 216), ('human', 217), ('development', 218), ('index', 219), ('enjoy', 220), ('life', 221), ('expectancy', 222), ('third', 223), ('lowest', 224), ('infant', 225), ('mortality', 226), ('rate', 227), ('experience', 228), ('issue', 229), ('due', 230), ('aging', 231), ('low', 232), ('birthrate', 233), ('renowned', 234), ('historical', 235), ('extensive', 236), ('cinema', 237), ('influential', 238), ('music', 239), ('industry', 240), ('anime', 241), ('video', 242), ('gaming', 243), ('rich', 244), ('cuisine', 245), ('major', 246), ('contribution', 247), ('science', 248), ('technology', 249), ('america', 250), ('(usa)', 251), ('commonly', 252), ('know', 253), ('(us', 254), ('us)', 255), ('comprise', 256), ('federal', 257), ('district', 258), ('five', 259), ('self-governing', 260), ('territory', 261), ('various', 262), ('possessions[h]', 263), ('square', 264), ('mile', 265), ('(', 266), ('km)', 267), ('total', 268), ('area[d]', 269), ('slightly', 270), ('smaller', 271), ('entire', 272), (\"europe's\", 273), ('us', 274), ('washington', 275), ('dc', 276), ('new', 277), ('york', 278), ('forty-eight', 279), (\"capital's\", 280), ('contiguous', 281), ('canada', 282), ('mexico', 283), ('alaska', 284), ('northwest', 285), ('corner', 286), ('border', 287), ('across', 288), ('bering', 289), ('strait', 290), ('russia', 291), ('hawaii', 292), ('mid-pacific', 293), ('scatter', 294), ('caribbean', 295), ('stretching', 296), ('nine', 297), ('official', 298), ('time', 299), ('zone', 300), ('extremely', 301), ('diverse', 302), ('geography', 303), ('climate', 304), ('wildlife', 305), ('megadiverse', 306), ('paleo-indian', 307), ('migrate', 308), ('siberia', 309), ('american', 310), ('mainland', 311), ('least', 312), ('years', 313), ('ago', 314), ('european', 315), ('colonization', 316), ('begin', 317), ('emerge', 318), ('thirteen', 319), ('british', 320), ('colony', 321), ('along', 322), ('french', 323), ('indian', 324), ('numerous', 325), ('dispute', 326), ('britain', 327), ('revolution', 328), ('subsequent', 329), ('declaration', 330), ('independence', 331), ('become', 332), ('gain', 333), ('current', 334), ('ten', 335), ('amendment', 336), ('collectively', 337), ('bill', 338), ('ratify', 339), ('guarantee', 340), ('many', 341), ('fundamental', 342), ('civil', 343), ('liberty', 344), ('embark', 345), ('vigorous', 346), ('expansion', 347), ('throughout', 348), ('acquiring', 349), ('displace', 350), ('native', 351), ('tribe', 352), ('gradually', 353), ('admit', 354), ('span', 355), ('half', 356), ('abolition', 357), ('slavery', 358), ('extend', 359), ('drive', 360), ('industrial', 361), ('soar', 362), ('spanishâ€“american', 363), ('confirm', 364), (\"country's\", 365), ('status', 366), ('global', 367), ('superpower', 368), ('nuclear', 369), ('weapon', 370), ('warfare', 371), ('permanent', 372), ('nation', 373), ('security', 374), ('council', 375), ('sweeping', 376), ('legislation', 377), ('notably', 378), ('act', 379), ('voting', 380), ('fair', 381), ('housing', 382), ('outlaw', 383), ('discrimination', 384), ('base', 385), ('race', 386), ('color', 387), ('cold', 388), ('soviet', 389), ('union', 390), ('compete', 391), ('space', 392), ('culminate', 393), ('moon', 394), ('landing', 395), ('collapse', 396), ('left', 397), ('sole', 398), ('old', 399), ('survive', 400), ('federation', 401), ('republic', 402), ('representative', 403), ('democracy', 404), ('founding', 405), ('bank', 406), ('international', 407), ('monetary', 408), ('fund', 409), ('organization', 410), ('(oas)', 411), ('second-largest', 412), ('ppp', 413), ('accounting', 414), ('approximately', 415), ('quarter', 416), ('largely', 417), ('post-industrial', 418), ('dominance', 419), ('services', 420), ('knowledge-based', 421), ('activity', 422), ('manufacturing', 423), ('sector', 424), ('remains', 425), ('good', 426), ('value', 427), ('hold', 428), ('wealth', 429), ('share', 430), ('concentrate', 431), ('single', 432), ('despite', 433), ('income', 434), ('disparity', 435), ('continue', 436), ('measure', 437), ('socioeconomic', 438), ('performance', 439), ('include', 440), ('average', 441), ('wage', 442), ('per', 443), ('caput', 444), ('worker', 445), ('productivity', 446), ('foremost', 447), ('making', 448), ('spending', 449), ('leading', 450), ('cultural', 451), ('scientific', 452), ('force', 453), ('internationally', 454), ('england', 455), ('kingdom', 456), ('wales', 457), ('scotland', 458), ('irish', 459), ('celtic', 460), ('southwest', 461), ('separate', 462), ('continental', 463), ('english', 464), ('channel', 465), ('cover', 466), ('five-eighths', 467), ('atlantic', 468), ('isle', 469), ('scilly', 470), ('wight', 471), ('humans', 472), ('palaeolithic', 473), ('take', 474), ('angle', 475), ('germanic', 476), ('deriving', 477), ('anglia', 478), ('peninsula', 479), ('settle', 480), ('unify', 481), ('age', 482), ('discovery', 483), ('significant', 484), ('legal', 485), ('impact', 486), ('wide', 487), ('language', 488), ('anglican', 489), ('church', 490), ('law', 491), ('basis', 492), ('common', 493), ('system', 494), ('around', 495), ('government', 496), ('widely', 497), ('th-century', 498), ('transform', 499), ('society', 500), ('industrialise', 501), (\"england's\", 502), ('terrain', 503), ('chiefly', 504), ('hill', 505), ('plain', 506), ('especially', 507), ('central', 508), ('southern', 509), ('however', 510), ('upland', 511), ('mountainous', 512), ('(for', 513), ('example', 514), ('lake', 515), ('pennines)', 516), ('dartmoor', 517), ('shropshire', 518), ('hills)', 519), ('london', 520), ('union[nb', 521), (']', 522), ('conurbation', 523), ('midland', 524), ('yorkshire', 525), ('cease', 526), ('acts', 527), ('put', 528), ('effect', 529), ('terms', 530), ('agree', 531), ('treaty', 532), ('previous', 533), ('year', 534), ('result', 535), ('create', 536), ('ireland', 537), ('(through', 538), ('another', 539), ('union)', 540), ('free', 541), ('secede', 542), ('latter', 543), ('rename', 544), ('northern', 545), (\"people's\", 546), ('(prc)', 547), ('billion', 548), ('covering', 549), ('kilometer', 550), ('sq', 551), ('mi)', 552), ('third-', 553), ('area[k]', 554), ('governed', 555), ('communist', 556), ('party', 557), ('exercise', 558), ('jurisdiction', 559), ('province', 560), ('autonomous', 561), ('direct-controlled', 562), ('municipality', 563), ('(beijing', 564), ('tianjin', 565), ('shanghai', 566), ('chongqing)', 567), ('special', 568), ('administrative', 569), ('hong', 570), ('kong', 571), ('macau', 572), ('earliest', 573), ('civilization', 574), ('fertile', 575), ('basin', 576), ('yellow', 577), ('river', 578), ('millennium', 579), (\"china's\", 580), ('hereditary', 581), ('dynasty', 582), ('beginning', 583), ('semi-legendary', 584), ('xia', 585), ('bce', 586), ('fracture', 587), ('re-unified', 588), ('times', 589), ('rd', 590), ('qin', 591), ('reunite', 592), ('core', 593), ('succeed', 594), ('han', 595), ('bc', 596), ('saw', 597), ('advance', 598), ('papermaking', 599), ('compass', 600), ('agricultural', 601), ('medical', 602), ('improvement', 603), ('invention', 604), ('gunpowder', 605), ('movable', 606), ('type', 607), ('tang', 608), ('(â€“)', 609), ('song', 610), ('complete', 611), ('culture', 612), ('spread', 613), ('silk', 614), ('route', 615), ('bring', 616), ('trader', 617), ('far', 618), ('mesopotamia', 619), ('horn', 620), ('africa', 621), ('dynastic', 622), ('xinhai', 623), ('replace', 624), ('qing', 625), ('whole', 626), ('ravage', 627), ('division', 628), ('one-party', 629), ('majority', 630), ('kuomintang-led', 631), ('nationalist', 632), ('retreated', 633), ('taiwan', 634), ('introduction', 635), ('economic', 636), ('reform', 637), ('fastest-growing', 638), ('annual', 639), ('growth', 640), ('rates', 641), ('consistently', 642), ('accord', 643), ('grow', 644), ('$', 645), ('trillion', 646), ('data', 647), ('yuan', 648), ('($', 649), ('trillion)', 650), ('(ppp)', 651), ('recognize', 652), ('standing', 653), ('army', 654), ('defense', 655), ('prc', 656), ('roc', 657), ('well', 658), ('active', 659), ('partner', 660), ('formal', 661), ('informal', 662), ('multilateral', 663), ('cooperation', 664), ('(sco)', 665), ('wto', 666), ('apec', 667), ('brics', 668), ('bcim', 669), ('rival', 670), ('india', 671), ('india[e]', 672), ('seventh-largest', 673), ('second-most', 674), ('bound', 675), ('arabian', 676), ('bay', 677), ('bengal', 678), ('southeast', 679), ('pakistan', 680), ('west;[f]', 681), ('nepal', 682), ('bhutan', 683), ('northeast;', 684), ('bangladesh', 685), ('myanmar', 686), ('vicinity', 687), ('sri', 688), ('lanka', 689), ('maldives;', 690), ('andaman', 691), ('nicobar', 692), ('maritime', 693), ('thailand', 694), ('indonesia', 695), ('subcontinent', 696), ('indus', 697), ('valley', 698), ('civilisation', 699), ('bronze', 700), (\"india's\", 701), ('iron', 702), ('scripture', 703), ('hinduism', 704), ('compose', 705), ('social', 706), ('stratification', 707), ('caste', 708), ('buddhism', 709), ('jainism', 710), ('arise', 711), ('consolidation', 712), ('place', 713), ('maurya', 714), ('gupta', 715), ('empires;', 716), ('peninsular', 717), ('middle', 718), ('medieval', 719), ('era', 720), ('judaism', 721), ('zoroastrianism', 722), ('christianity', 723), ('islam', 724), ('arrive', 725), ('sikhism', 726), ('add', 727), ('fell', 728), ('delhi', 729), ('sultanate;', 730), ('vijayanagara', 731), ('expansive', 732), ('mughal', 733), ('company', 734), ('mark', 735), ('crown', 736), ('movement', 737), ('mahatma', 738), ('gandhi', 739), ('note', 740), ('nonviolence', 741), ('liberalisation', 742), ('cause', 743), ('fast', 744), ('growing', 745), ('newly', 746), ('gross', 747), ('domestic', 748), ('product', 749), ('sixth', 750), ('market', 751), ('exchange', 752), ('face', 753), ('challenge', 754), ('poverty', 755), ('corruption', 756), ('malnutrition', 757), ('inadequate', 758), ('public', 759), ('healthcare', 760), ('regional', 761), ('expenditure', 762), ('secular', 763), ('democratic', 764), ('administer', 765), ('seven', 766), ('pluralistic', 767), ('multilingual', 768), ('multi-ethnic', 769), ('diversity', 770), ('variety', 771), ('protect', 772), ('habitat', 773), ('korea', 774), ('distinct', 775), ('korean', 776), ('jeju', 777), ('minor', 778), ('near', 779), ('northeast', 780), ('via', 781), ('(east', 782), ('sea)', 783), ('three', 784), ('goguryeo', 785), ('baekje', 786), ('silla', 787), ('together', 788), ('\"three', 789), ('korea\"', 790), ('defeated', 791), ('conquer', 792), ('\"unified', 793), ('silla\"', 794), ('meanwhile', 795), ('balhae', 796), ('form', 797), ('supersede', 798), ('former', 799), ('eventually', 800), ('usher', 801), ('later', 802), ('toward', 803), ('resurrect', 804), ('goryeo', 805), ('last', 806), ('prince', 807), ('flee', 808), ('(also', 809), ('spell', 810), ('koryÅ)', 811), ('whose', 812), ('exonym', 813), ('\"korea\"', 814), ('metal', 815), ('multiple', 816), ('incursion', 817), ('mongol', 818), ('greatly', 819), ('weaken', 820), ('vassal', 821), ('fighting', 822), ('resistance', 823), ('king', 824), ('gongmin', 825), ('severe', 826), ('strife', 827), ('coup', 828), ('general', 829), ('yi', 830), ('seong-gye', 831), ('joseon', 832), ('july', 833), ('relative', 834), ('peace', 835), ('alphabet', 836), ('sejong', 837), ('confucianism', 838), (\"korea's\", 839), ('isolationist', 840), ('policy', 841), ('earn', 842), ('nickname', 843), ('\"hermit', 844), ('kingdom\"', 845), ('object', 846), ('design', 847), (\"empire's\", 848), ('effort', 849), ('modernize', 850), ('annex', 851), ('august', 852), ('aftermath', 853), ('leaving', 854), ('partition', 855), ('parallel', 856), ('circumstances', 857), ('soon', 858), ('exacerbate', 859), ('inability', 860), ('communist-inspired', 861), ('receive', 862), ('backing', 863), ('opposition', 864), ('pro-western', 865), ('entities:', 866), ('(officially', 867), ('korea)', 868), ('tension', 869), ('outbreak', 870), ('involvement', 871), ('foreign', 872), ('troops', 873), ('stalemate', 874), ('without', 875), ('formalize', 876), ('contribute', 877), ('claim', 878), ('legitimate', 879), ('germany', 880), ('lying', 881), ('baltic', 882), ('alps', 883), ('constance', 884), ('rhine', 885), ('denmark', 886), ('poland', 887), ('czech', 888), ('austria', 889), ('switzerland', 890), ('france', 891), ('luxembourg', 892), ('belgium', 893), ('netherlands', 894), ('constituent', 895), ('kilometre', 896), ('temperate', 897), ('seasonal', 898), ('inhabitant', 899), ('entirely', 900), ('decentralize', 901), ('metropolis', 902), ('berlin', 903), ('frankfurt', 904), ('serve', 905), ('financial', 906), ('busy', 907), ('airport', 908), (\"germany's\", 909), ('urban', 910), ('ruhr', 911), ('main', 912), ('centre', 913), ('dortmund', 914), ('essen', 915), ('hamburg', 916), ('munich', 917), ('cologne', 918), ('stuttgart', 919), ('dÃ¼sseldorf', 920), ('leipzig', 921), ('dresden', 922), ('bremen', 923), ('hannover', 924), ('nuremberg', 925), ('mannheim', 926), ('parts', 927), ('classical', 928), ('antiquity', 929), ('germania', 930), ('document', 931), ('migration', 932), ('southward', 933), ('german', 934), ('holy', 935), ('roman', 936), ('protestant', 937), ('reformation', 938), ('confederation', 939), ('parliament', 940), ('(except', 941), ('austria)', 942), ('prussian-dominated', 943), ('weimar', 944), ('nazi', 945), ('seizure', 946), ('establishment', 947), ('dictatorship', 948), ('annexation', 949), ('holocaust', 950), ('ally', 951), ('re-established', 952), ('independent', 953), ('founded:', 954), ('pre-war', 955), ('explusion', 956), ('reunify', 957), ('october', 958), ('today', 959), ('chancellor', 960), ('strong', 961), ('economy;', 962), ('fifth-largest', 963), ('leader', 964), ('technological', 965), ('uphold', 966), ('universal', 967), ('health', 968), ('care', 969), ('environmental', 970), ('protection', 971), ('tuition-free', 972), ('university', 973), ('community', 974), ('schengen', 975), ('co-founder', 976), ('eurozone', 977), ('nato', 978), ('continuously', 979), ('successful', 980), ('artist', 981), ('philosopher', 982), ('musician', 983), ('film', 984), ('sportspeople', 985), ('entrepreneur', 986), ('scientist', 987), ('engineer', 988), ('inventor', 989), ('number', 990), ('heritage', 991), ('site', 992), ('top', 993), ('tourism', 994), ('destination', 995), ('russian', 996), ('transcontinental', 997), ('considerable', 998), ('margin', 999), ('one-eighth', 1000), (\"earth's\", 1001), ('ninth', 1002), ('crimea', 1003), (\"russia's\", 1004), ('moscow', 1005), ('europe;', 1006), ('saint', 1007), ('petersburg', 1008), ('novosibirsk', 1009), ('yekaterinburg', 1010), ('nizhny', 1011), ('novgorod', 1012), ('entirety', 1013), ('much', 1014), ('eleven', 1015), ('incorporate', 1016), ('range', 1017), ('environment', 1018), ('landforms', 1019), ('norway', 1020), ('finland', 1021), ('estonia', 1022), ('latvia', 1023), ('lithuania', 1024), ('(both', 1025), ('kaliningrad', 1026), ('oblast)', 1027), ('belarus', 1028), ('ukraine', 1029), ('georgia', 1030), ('azerbaijan', 1031), ('kazakhstan', 1032), ('mongolia', 1033), ('recognise', 1034), ('abkhazia', 1035), ('ossetia', 1036), ('slav', 1037), ('recognizable', 1038), ('group', 1039), ('found', 1040), ('varangian', 1041), ('warrior', 1042), ('elite', 1043), ('descendants', 1044), ('rus', 1045), ('orthodox', 1046), ('byzantine', 1047), ('synthesis', 1048), ('slavic', 1049), ('define', 1050), ('next', 1051), ('ultimately', 1052), ('disintegrate', 1053), ('states;', 1054), (\"rus'\", 1055), ('overrun', 1056), ('invasion', 1057), ('tributary', 1058), ('nomadic', 1059), ('golden', 1060), ('horde', 1061), ('grand', 1062), ('duchy', 1063), ('surround', 1064), ('principality', 1065), ('achieve', 1066), ('conquest', 1067), ('exploration', 1068), ('federative', 1069), ('socialist', 1070), ('constitutionally', 1071), ('play', 1072), ('decisive', 1073), ('role', 1074), ('achievement', 1075), ('human-made', 1076), ('satellite', 1077), ('launching', 1078), ('stockpile', 1079), ('mass', 1080), ('destruction', 1081), ('dissolution', 1082), ('twelve', 1083), ('ussr:', 1084), ('uzbekistan', 1085), ('armenia', 1086), ('kyrgyzstan', 1087), ('moldova', 1088), ('tajikistan', 1089), ('turkmenistan', 1090), ('independence:', 1091), ('lithuania;', 1092), ('sfsr', 1093), ('reconstitute', 1094), ('personality', 1095), ('successor', 1096), ('semi-presidential', 1097), ('twelfth', 1098), ('mineral', 1099), ('energy', 1100), ('resource', 1101), ('reserves', 1102), ('producer', 1103), ('oil', 1104), ('natural', 1105), ('gas', 1106), ('globally', 1107), ('posse', 1108), ('characterise', 1109), ('potential', 1110), ('organisation', 1111), ('asia-pacific', 1112), ('(apec)', 1113), ('co-operation', 1114), ('(osce)', 1115), ('trade', 1116), ('(wto)', 1117), ('commonwealth', 1118), ('(cis)', 1119), ('collective', 1120), ('(csto)', 1121), ('eurasian', 1122), ('(eeu)', 1123), ('overseas', 1124), ('territories[xiii]', 1125), ('mediterranean', 1126), ('italy', 1127), ('andorra', 1128), ('spain', 1129), ('guiana', 1130), ('integral', 1131), ('combine', 1132), ('(as', 1133), (')', 1134), ('paris', 1135), ('commercial', 1136), ('lyon', 1137), ('marseille', 1138), ('toulouse', 1139), ('bordeaux', 1140), ('lille', 1141), ('nice', 1142), ('gaul', 1143), ('rome', 1144), ('arrival', 1145), ('frank', 1146), ('francia', 1147), ('verdun', 1148), ('hundred', 1149), (\"years'\", 1150), ('renaissance', 1151), ('flourish', 1152), ('colonial', 1153), ('would', 1154), ('dominate', 1155), ('religious', 1156), ('catholic', 1157), ('(huguenots)', 1158), ('dominant', 1159), ('louis', 1160), ('xiv', 1161), ('overthrow', 1162), ('absolute', 1163), (\"history's\", 1164), ('drafting', 1165), ('man', 1166), ('express', 1167), (\"nation's\", 1168), ('ideal', 1169), ('day', 1170), ('napoleon', 1171), ('napoleonic', 1172), ('shape', 1173), ('course', 1174), ('endure', 1175), ('tumultuous', 1176), ('succession', 1177), ('participant', 1178), ('victorious', 1179), ('allies', 1180), ('axis', 1181), ('liberation', 1182), ('dissolve', 1183), ('algerian', 1184), ('fifth', 1185), ('charles', 1186), ('de', 1187), ('gaulle', 1188), ('algeria', 1189), ('typically', 1190), ('retain', 1191), ('close', 1192), ('connection', 1193), ('art', 1194), ('philosophy', 1195), ('host', 1196), ('unesco', 1197), ('tourist', 1198), ('visitor', 1199), ('annually', 1200), ('sixth-largest', 1201), ('tenth-largest', 1202), ('aggregate', 1203), ('household', 1204), ('perform', 1205), ('ranking', 1206), ('affairs', 1207), ('veto', 1208), ('nuclear-weapon', 1209), ('(nato)', 1210), ('(oecd)', 1211), ('la', 1212), ('francophonie', 1213), ('italian', 1214), ('delimit', 1215), ('traverse', 1216), ('length', 1217), ('apennines', 1218), ('km', 1219), ('slovenia', 1220), ('enclaved', 1221), ('microstates', 1222), ('vatican', 1223), ('san', 1224), ('marino', 1225), ('territorial', 1226), ('exclave', 1227), ('(campione)', 1228), ('tunisian', 1229), ('(lampedusa)', 1230), ('fourth-most', 1231), ('geographic', 1232), ('location', 1233), ('historically', 1234), ('myriad', 1235), ('ancient', 1236), ('peoples', 1237), ('predominant', 1238), ('indo-european', 1239), ('italic', 1240), ('give', 1241), ('latin', 1242), ('senate', 1243), ('inaugurate', 1244), ('pax', 1245), ('romana', 1246), (\"italy's\", 1247), ('literature', 1248), ('remain', 1249), ('homeland', 1250), ('romans', 1251), ('metropole', 1252), ('legacy', 1253), ('observe', 1254), ('distribution', 1255), ('script', 1256), ('sociopolitical', 1257), ('barbarian', 1258), ('city-state', 1259), ('rose', 1260), ('prosperity', 1261), ('commerce', 1262), ('banking', 1263), ('laying', 1264), ('groundwork', 1265), ('capitalism', 1266), ('rest', 1267), ('bringing', 1268), ('renew', 1269), ('interest', 1270), ('humanism', 1271), ('produce', 1272), ('famous', 1273), ('scholar', 1274), ('polymath', 1275), ('explorer', 1276), ('discover', 1277), ('helping', 1278), ('nevertheless', 1279), ('significantly', 1280), ('wane', 1281), ('opening', 1282), ('bypass', 1283), ('infighting', 1284), ('fragment', 1285), ('subsequently', 1286), ('mid-th', 1287), ('nationalism', 1288), ('control', 1289), ('revolutionary', 1290), ('upheaval', 1291), ('domination', 1292), ('almost', 1293), ('rapidly', 1294), ('namely', 1295), ('acquire', 1296), ('impoverish', 1297), ('exclude', 1298), ('industrialisation', 1299), ('fuel', 1300), ('diaspora', 1301), ('victor', 1302), ('crisis', 1303), ('turmoil', 1304), ('rise', 1305), ('fascist', 1306), ('participation', 1307), ('side', 1308), ('defeat', 1309), ('abolish', 1310), ('prolong', 1311), ('boom', 1312), ('culturally', 1313), ('economically', 1314), ('worldwide', 1315), ('gold', 1316), ('reserve', 1317), ('prominent', 1318), ('diplomatic', 1319), ('affairs;', 1320), ('eighth', 1321), ('institution', 1322), ('osce', 1323), ('uniting', 1324), ('consensus', 1325), ('fields', 1326), ('arts', 1327), ('fashion', 1328), ('sport', 1329), ('jurisprudence', 1330), ('business', 1331), ('reflection', 1332), ('()', 1333), ('fifth-most', 1334), ('visit', 1335), ('brazil', 1336), ('miles)', 1337), ('brasÃ­lia', 1338), ('populate', 1339), ('sÃ£o', 1340), ('paulo', 1341), ('portuguese', 1342), ('americas;', 1343), ('multicultural', 1344), ('ethnically', 1345), ('immigration', 1346), ('coastline', 1347), ('except', 1348), ('ecuador', 1349), ('chile', 1350), (\"continent's\", 1351), ('amazon', 1352), ('vast', 1353), ('tropical', 1354), ('forest', 1355), ('ecological', 1356), ('unique', 1357), ('subject', 1358), ('debate', 1359), ('regard', 1360), ('deforestation', 1361), ('tribal', 1362), ('prior', 1363), ('pedro', 1364), ('Ã¡lvares', 1365), ('cabral', 1366), ('transfer', 1367), ('lisbon', 1368), ('rio', 1369), ('janeiro', 1370), ('elevated', 1371), ('upon', 1372), ('formation', 1373), ('portugal', 1374), ('algarves', 1375), ('creation', 1376), ('ratification', 1377), ('bicameral', 1378), ('congress', 1379), ('presidential', 1380), (\"d'Ã©tat\", 1381), ('authoritarian', 1382), ('junta', 1383), ('civilian', 1384), ('governance', 1385), ('resume', 1386), (\"brazil's\", 1387), ('formulate', 1388), ('thirteenth', 1389), ('breadbasket', 1390), ('coffee', 1391), ('classified', 1392), ('upper-middle', 1393), ('industrialize', 1394), ('sometimes', 1395), ('account', 1396), ('recognition', 1397), ('analyst', 1398), ('mercosul', 1399), ('ibero-american', 1400), ('northward', 1401), ('arctic', 1402), (\"canada's\", 1403), ('bi-national', 1404), ('ottawa', 1405), ('toronto', 1406), ('montreal', 1407), ('vancouver', 1408), ('sparsely', 1409), ('tundra', 1410), ('consequently', 1411), ('urbanize', 1412), ('medium-sized', 1413), ('reside', 1414), ('within', 1415), ('vary', 1416), ('weather', 1417), ('hot', 1418), ('summer', 1419), ('season', 1420), ('indigenous', 1421), ('thousand', 1422), ('expedition', 1423), ('explore', 1424), ('consequence', 1425), ('arm', 1426), ('cede', 1427), ('dominion', 1428), ('accretion', 1429), ('process', 1430), ('autonomy', 1431), ('widening', 1432), ('highlight', 1433), ('statute', 1434), ('westminster', 1435), ('sever', 1436), ('vestige', 1437), ('dependence', 1438), ('tradition', 1439), ('elizabeth', 1440), ('queen', 1441), ('prime', 1442), ('minister', 1443), ('chair', 1444), ('cabinet', 1445), ('head', 1446), ('realm', 1447), ('bilingual', 1448), ('level', 1449), ('measurement', 1450), ('transparency', 1451), ('quality', 1452), ('freedom', 1453), ('large-scale', 1454), ('complex', 1455), ('relationship', 1456), ('sixteenth-highest', 1457), ('twelfth-highest', 1458), ('rely', 1459), ('abundant', 1460), ('well-developed', 1461), ('network', 1462), ('intergovernmental', 1463), ('grouping', 1464), ('(formerly', 1465), ('g)', 1466), ('agreement', 1467), ('forum', 1468), ('spain[a][b]', 1469), ('mostly', 1470), ('situate', 1471), ('iberian', 1472), ('archipelagoes:', 1473), ('canary', 1474), ('balearic', 1475), ('african', 1476), ('enclave', 1477), ('ceuta', 1478), ('melilla', 1479), ('peÃ±Ã³n', 1480), ('vÃ©lez', 1481), ('gomera', 1482), ('physical', 1483), ('(morocco)[h]', 1484), ('small', 1485), ('alboran', 1486), ('spanish', 1487), ('boundary', 1488), ('gibraltar;', 1489), ('biscay;', 1490), (\"spain's\", 1491), ('madrid;', 1492), ('barcelona', 1493), ('valencia', 1494), ('seville', 1495), ('mÃ¡laga', 1496), ('bilbao', 1497), ('phoenician', 1498), ('greek', 1499), ('carthaginian', 1500), ('settlement', 1501), ('hispania', 1502), ('earlier', 1503), ('spn', 1504), ('spania', 1505), ('invade', 1506), ('relatively', 1507), ('suebi', 1508), ('alans', 1509), ('vandal', 1510), ('visigoth', 1511), ('forcibly', 1512), ('integrate', 1513), ('toledo', 1514), ('le', 1515), ('politically', 1516), ('ecclesiastically', 1517), ('legally', 1518), ('visigothic', 1519), ('moor', 1520), ('umayyad', 1521), ('islamic', 1522), ('caliphate', 1523), ('handful', 1524), ('christian', 1525), ('granada', 1526), ('reconquer', 1527), ('leon', 1528), ('castille', 1529), ('aragon', 1530), ('navarre', 1531), ('moorish', 1532), ('gradual', 1533), ('retaking', 1534), ('reconquista', 1535), ('emergence', 1536), ('monarch', 1537), ('powerful', 1538), ('linguistic', 1539), ('+', 1540), ('hispanophones', 1541), ('speak', 1542), ('mandarin', 1543), ('advancement', 1544), ('world-famous', 1545), ('painter', 1546), ('diego', 1547), ('velÃ¡zquez', 1548), ('literary', 1549), ('work', 1550), ('quixote', 1551), ('publish', 1552), ('felipe', 1553), ('vi', 1554), ('fourteenth', 1555), ('sixteenth', 1556), ('(un)', 1557), ('(eu)', 1558), ('(coe)', 1559), ('(oei)', 1560), ('\"permanent', 1561), ('invitation\"', 1562), ('summit', 1563), ('participate', 1564), ('every', 1565), ('facto', 1566), ('australia', 1567), ('australian', 1568), ('tasmania', 1569), ('oceania', 1570), ('neighbour', 1571), ('papua', 1572), ('guinea', 1573), ('timor', 1574), ('north;', 1575), ('solomon', 1576), ('vanuatu', 1577), ('north-east;', 1578), ('zealand', 1579), ('south-east', 1580), ('urbanise', 1581), ('heavily', 1582), ('seaboard', 1583), (\"australia's\", 1584), ('canberra', 1585), ('sydney', 1586), ('melbourne', 1587), ('brisbane', 1588), ('perth', 1589), ('adelaide', 1590), ('dutch', 1591), ('holland', 1592), ('initially', 1593), ('penal', 1594), ('transportation', 1595), ('january', 1596), ('date', 1597), ('steadily', 1598), ('rush', 1599), ('additional', 1600), ('six', 1601), ('federate', 1602), ('stable', 1603), ('liberal', 1604), ('function', 1605), ('flat', 1606), ('dry', 1607), ('soil', 1608), ('landmass', 1609), ('size', 1610), ('landscape', 1611), ('deserts', 1612), ('rainforest', 1613), ('north-east', 1614), ('mountain', 1615), ('density', 1616), ('generate', 1617), ('source', 1618), ('mining-related', 1619), ('export', 1620), ('telecommunication', 1621), ('th-largest', 1622), ('high-income', 1623), ('tenth-highest', 1624), ('th-highest', 1625), ('immigrant', 1626), ('third-highest', 1627), ('eighth-highest', 1628), ('fare', 1629), ('comparative', 1630), ('livability', 1631), ('survey', 1632), ('anzus', 1633), ('(indonesian:', 1634), ('republik', 1635), ('[reËˆpublik', 1636), ('ÉªndoËˆnesia])[a]', 1637), ('seventeen', 1638), ('muslim-majority', 1639), ('java', 1640), ('jakarta', 1641), ('malaysia', 1642), ('singapore', 1643), ('vietnam', 1644), ('philippines', 1645), ('palau', 1646), ('densely', 1647), ('wilderness', 1648), ('support', 1649), ('biodiversity', 1650), ('like', 1651), ('tin', 1652), ('copper', 1653), ('agriculture', 1654), ('rice', 1655), ('palm', 1656), ('tea', 1657), ('cacao', 1658), ('medicinal', 1659), ('plant', 1660), ('spice', 1661), ('rubber', 1662), (\"indonesia's\", 1663), ('trading', 1664), ('indonesian', 1665), ('draw', 1666), ('important', 1667), ('srivijaya', 1668), ('majapahit', 1669), ('entity', 1670), ('local', 1671), ('ruler', 1672), ('absorb', 1673), ('model', 1674), ('hindu', 1675), ('buddhist', 1676), ('muslim', 1677), ('sufi', 1678), ('fight', 1679), ('monopolise', 1680), ('maluku', 1681), ('interrupt', 1682), ('-year', 1683), ('presence', 1684), ('concept', 1685), ('\"indonesia\"', 1686), ('decolonisation', 1687), ('largestâ€”and', 1688), ('dominantâ€”ethnic', 1689), ('javanese', 1690), ('identity', 1691), ('pluralism', 1692), ('colonialism', 1693), ('rebellion', 1694), ('motto', 1695), ('\"bhinneka', 1696), ('tunggal', 1697), ('ika\"', 1698), ('(\"unity', 1699), ('diversity\"', 1700), ('literally', 1701), ('\"many', 1702), ('yet', 1703), ('one\")', 1704), ('articulate', 1705), ('un[b]', 1706), ('imf', 1707), ('non-aligned', 1708), ('association', 1709), ('infrastructure', 1710), ('investment', 1711), ('mexican', 1712), ('(spanish:', 1713), ('estados', 1714), ('unidos', 1715), ('mexicano', 1716), ('portion', 1717), ('ocean;', 1718), ('guatemala', 1719), ('belize', 1720), ('sea;', 1721), ('gulf', 1722), ('estimate', 1723), ('tenth', 1724), ('spanish-speaking', 1725), ('guadalajara', 1726), ('monterrey', 1727), ('puebla', 1728), ('toluca', 1729), ('tijuana', 1730), ('leÃ³n', 1731), ('pre-columbian', 1732), ('identify', 1733), ('cradle', 1734), ('mesoamerican', 1735), ('olmec', 1736), ('toltec', 1737), ('teotihuacan', 1738), ('zapotec', 1739), ('maya', 1740), ('aztec', 1741), ('contact', 1742), ('colonize', 1743), ('mexico-tenochtitlan', 1744), ('(part', 1745), ('city)', 1746), ('viceroyalty', 1747), ('post-independence', 1748), ('inequality', 1749), ('contrast', 1750), ('change', 1751), ('mexicanâ€“american', 1752), ('cession', 1753), ('extant', 1754), ('pastry', 1755), ('franco-mexican', 1756), ('porfiriato', 1757), ('occur', 1758), ('promulgation', 1759), ('describe', 1760), ('\"perfect', 1761), ('dictatorship\"', 1762), ('electoral', 1763), (\"mexico's\", 1764), ('transition', 1765), ('strongly', 1766), ('link', 1767), ('(nafta)', 1768), ('seventh', 1769), ('ecologically', 1770), ('huge', 1771), ('year:', 1772), ('most-visited', 1773), ('g+', 1774), ('alliance', 1775), ('bloc', 1776)])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p73OT5sPs9y",
        "outputId": "6811fb4e-7112-44d2-fe71-9331d01548f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def calc_cosine(vector, vector_list):\n",
        "  result = {}\n",
        "  for i, x in enumerate(vector_list):\n",
        "    result[i] = cosine_similarity(vector, vector_list[i])\n",
        "    \n",
        "  return result\n",
        "\n",
        "print(\"tfidf\")\n",
        "res = calc_cosine(tfidf_vector[0],tfidf_vector)\n",
        "res"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfidf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0,\n",
              " 1: 0.04945156965230687,\n",
              " 2: 0.03550026859810149,\n",
              " 3: 0.07494324927746153,\n",
              " 4: 0.02200165046387345,\n",
              " 5: 0.089213868005443,\n",
              " 6: 0.04329186935344452,\n",
              " 7: 0.04340970910393382,\n",
              " 8: 0.050616794433693456,\n",
              " 9: 0.05446867547327852,\n",
              " 10: 0.03479541972998953,\n",
              " 11: 0.03392463518350004,\n",
              " 12: 0.038469390607195876,\n",
              " 13: 0.05035814117836253,\n",
              " 14: 0.06794378321355649,\n",
              " 15: 0.029516361108928312}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMGEF5UJUZSz",
        "outputId": "0c135370-113a-4dfe-fec5-1e175efcbbdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sorted(res.items(), key=lambda x:x[1],reverse=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1.0),\n",
              " (5, 0.089213868005443),\n",
              " (3, 0.07494324927746153),\n",
              " (14, 0.06794378321355649),\n",
              " (9, 0.05446867547327852),\n",
              " (8, 0.050616794433693456),\n",
              " (13, 0.05035814117836253),\n",
              " (1, 0.04945156965230687),\n",
              " (7, 0.04340970910393382),\n",
              " (6, 0.04329186935344452),\n",
              " (12, 0.038469390607195876),\n",
              " (2, 0.03550026859810149),\n",
              " (10, 0.03479541972998953),\n",
              " (11, 0.03392463518350004),\n",
              " (15, 0.029516361108928312),\n",
              " (4, 0.02200165046387345)]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OWm8pnAMQH-"
      },
      "source": [
        "## Option 3\n",
        "\n",
        "### Word2Vec & Doc2Vec\n",
        "\n",
        "Word2Vecã‚„Doc2Vecã§ã¯å˜èªã®æ„å‘³ã‚’æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã‹ã®ã‚ˆã†ãªæ¼”ç®—ãŒå‡ºæ¥ã‚‹  \n",
        "King - Man + Woman = Queen ãªã©  \n",
        "è©³ç´°ã¯è¬›ç¾©ã‚¹ãƒ©ã‚¤ãƒ‰ã¸   \n",
        "\n",
        "å­¦ç¿’æ¸ˆã¿ã®word2vecãŒgithub( https://github.com/Kyubyong/wordvectors )ã«ä¸ŠãŒã£ã¦ã„ã‚‹ã®ã§  \n",
        "æ—¥æœ¬ã¨å„å›½ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†  \n",
        "è¶³ã—ç®—ã‚„å¼•ãç®—ãŒå‡ºæ¥ã‚‹ã®ã§ãã‚Œã‚‚è©¦ã—ã¦ã¿ã‚ˆã†  \n",
        "\n",
        "å‚è€ƒ : \"BOKU\"ã®ITãªæ—¥å¸¸ (https://arakan-pgm-ai.hatenablog.com/entry/2019/02/08/090000)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWddZ1mZXFsv"
      },
      "source": [
        ""
      ],
      "execution_count": 67,
      "outputs": []
    }
  ]
}